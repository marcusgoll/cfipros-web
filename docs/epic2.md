# Epic 2: FAA Knowledge Test Extraction & Basic Reporting

**Epic Number:** 2
**Title:** FAA Knowledge Test Extraction & Basic Reporting
**Status:** To Do
**Priority:** Critical
**Product Owner:** TBD
**Assigned Team:** TBD
**Sprint Allocation:** Sprint 2-4 (Estimate)

**Goal:** Develop the core tool for uploading FAA Knowledge Test PDFs/images, processing them via Gemini API for OCR, matching data to ACS codes, and allowing users to view extracted results and export a basic PDF report. This will provide the primary value proposition for students and instructors.

**Description:**
This epic focuses on building the central feature of CFIPros: the FAA Knowledge Test Extraction Tool. Users (initially Students, but CFIs/Schools can also use it) will be able to upload their test result documents. The system will use the Gemini API for OCR to extract textual data, then match this data (specifically the missed question codes or learning statement codes) to an internal database of Airman Certification Standards (ACS) codes. The processed results, including descriptions of the ACS codes, will be displayed to the user and made available for export as a formatted PDF report. This PDF will also include summary statistics if multiple tests for a student are available.

**User Stories:**

| Story ID | User Story                                                                                                                                                 | Acceptance Criteria                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Priority | Estimate | Status | Dependencies | Notes                                                                                                                                         |
| :------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------- | :------- | :----- | :----------- | :-------------------------------------------------------------------------------------------------------------------------------------------- |
| E2-S1    | As a User (Student/CFI), I want to be able to upload my FAA Knowledge Test result document (PDF or image), so that it can be processed.                    | - UI provides a clear file upload area (drag & drop and/or browse).\<br\>- Accepts PDF, JPG, PNG file types.\<br\>- File size limits are enforced (e.g., \<10MB).\<br\>- User receives clear feedback on upload progress and success/failure.\<br\>- Uploaded file is securely transmitted to the backend for processing.                                                                                                                                                                      | Critical | 3 SP     | To Do  | E1 (Auth)    |                                                                                                                                               |
| E2-S2    | As a Developer, I want to integrate the Gemini API for OCR processing, so that text can be extracted from the uploaded test documents.                     | - Securely configure Gemini API key.\<br\>- Function created to send uploaded file (or its content) to Gemini Vision API for text extraction.\<br\>- Handles API responses, including errors from Gemini.\<br\>- Extracted text is retrieved and stored temporarily for parsing.                                                                                                                                                                                                               | Critical | 4 SP     | To Do  | E2-S1        | Requires research into Gemini API specifics for document OCR. Consider rate limits and costs.                                                 |
| E2-S3    | As a Developer, I want to create and populate an ACS (Airman Certification Standards) code database, so that extracted codes can be matched and described. | - Database table(s) created in Supabase for ACS codes (e.g., `acs_codes` with `code`, `description`, `test_type_association`, `knowledge_area`, etc.).\<br\>- Source for ACS codes identified and data imported/entered (e.g., from FAA publications).\<br\>- Mechanism to update ACS codes if they change over time (manual update for MVP is fine).                                                                                                                                          | Critical | 3 SP     | To Do  | E1-S2        | Data sourcing is key. Needs to cover various test types (PAR, IRA, CAX, etc.).                                                                |
| E2-S4    | As a Developer, I want to implement logic to parse the OCR output and match extracted data to ACS codes, so that test results are structured.              | - Algorithm developed to identify relevant sections in OCR text (e.g., list of missed questions/codes).\<br\>- Logic to match these identified codes/phrases against the `acs_codes` database.\<br\>- Handles variations in test report formats if possible.\<br\>- Stores the list of matched ACS codes (correct/incorrect if discernible) linked to the specific test and user.                                                                                                              | Critical | 5 SP     | To Do  | E2-S2, E2-S3 | This is a complex story with high risk of variability. Requires sample test reports.                                                          |
| E2-S5    | As a User, I want to see the processed results of my test, including the matched ACS codes and their descriptions, so that I understand my weak areas.     | - UI page displays the processed test information.\<br\>- Shows overall score (if extractable).\<br\>- Lists missed ACS codes with their official descriptions.\<br\>- Clearly indicates which areas the user struggled with.\<br\>- User-friendly and easy-to-understand presentation.                                                                                                                                                                                                        | Critical | 3 SP     | To Do  | E2-S4        |                                                                                                                                               |
| E2-S6    | As a User, I want the system to handle errors gracefully if my test document cannot be processed, so that I am informed and can try again.                 | - Clear error messages displayed if OCR fails (e.g., unreadable document).\<br\>- Clear error messages if no ACS codes can be matched (e.g., unsupported test type or format for MVP).\<br\>- Guidance on what might have gone wrong and suggestions for re-upload (e.g., better image quality).\<br\>- Original uploaded file is NOT stored long-term, especially on failure, per requirements.                                                                                               | High     | 2 SP     | To Do  | E2-S4        | No PII/file storage of original uploads long-term.                                                                                            |
| E2-S7    | As a User, I want to be able to export my processed test report as a formatted PDF, so that I can save or share it.                                        | - "Export to PDF" button available on the test results page.\<br\>- PDF includes student name, test date (if extractable), overall score, list of missed ACS codes and descriptions.\<br\>- PDF is professionally formatted and includes CFIPros branding.\<br\>- If multiple tests exist for student, PDF front cover includes summary statistics (e.g. trend graph or score summary over time - this part might be complex).                                                                 | High     | 4 SP     | To Do  | E2-S5        | PDF generation library needed (e.g., `pdf-lib` or serverless function with Puppeteer if complex layout needed). Summary stats add complexity. |
| E2-S8    | As a Developer, I want to store the extracted test data (not original files) and generated reports securely, linked to user accounts.                      | - `knowledge_tests` table in Supabase (stores `user_id`, `test_date`, `score`, extracted data like list of missed ACS codes as JSONB or linked table).\<br\>- `test_acs_items` table linking `knowledge_tests` to `acs_codes` (many-to-many, stores correct/incorrect status if available).\<br\>- Ensures that only extracted textual data is stored, no original PDF/images.\<br\>- Generated PDF reports could be stored temporarily or regenerated on demand (TBD). RLS policies in place. | Critical | 3 SP     | To Do  | E1-S3, E2-S4 | Decision: Regenerate PDF on demand for MVP to save storage, unless performance is an issue.                                                   |
| E2-S9    | As a Student, I want a "My Test Reports" page where I can view a list of all my processed test reports, so I can track my history.                         | - Page lists all knowledge tests processed by/for the logged-in student.\<br\>- Displays key info per test (e.g., test type, date, score).\<br\>- Allows clicking through to view the detailed report (E2-S5 UI).\<br\>- Option to re-download PDF for each report.                                                                                                                                                                                                                            | High     | 2 SP     | To Do  | E2-S8        |                                                                                                                                               |
| E2-S10   | As a Developer, I need to implement a fallback or review mechanism consideration for OCR accuracy, so that risks of inaccuracies are mitigated.            | - Log OCR confidence scores if available from Gemini.\<br\>- For MVP, if confidence is very low or key data fields are missing post-OCR, display a message to the user suggesting the quality of the upload might be an issue or data couldn't be fully extracted.\<br\>- No manual admin review for MVP. User can choose to delete and re-upload.                                                                                                                                             | Medium   | 2 SP     | To Do  | E2-S4        | Focus on clear communication to the user about potential issues.                                                                              |

**Out of Scope for this Epic:**

- Storing original uploaded PDF/image files long-term.
- Advanced analytics beyond individual test report breakdowns.
- Manual admin review or correction of extracted data.
- Direct CFI/School management of student tests (linking happens in Epic 3).

**Assumptions:**

- Gemini API can provide sufficiently accurate OCR for common FAA test report formats.
- A comprehensive list of ACS codes and their descriptions can be sourced and structured.
- Users will have access to their FAA Knowledge Test result documents in a supported format.

**Risks:**

- **OCR Accuracy & Variability:** FAA test reports might have diverse formats; OCR might struggle with some, impacting ACS code matching. This is the highest risk.
- **Gemini API Performance/Cost:** High volume or large files might lead to slow processing or unexpected costs.
- Complexity of parsing logic to accurately identify ACS codes from OCR text.

**Dependencies:**

- Completed User Authentication (Epic 1).
- Access to Gemini API.
- Availability of sample FAA Knowledge Test reports for testing various formats.
- UI/UX designs for the upload interface and results display.

**Metrics for Success:**

- > 95% accuracy in ACS code extraction for supported test formats.
- High user satisfaction with the ease of use and utility of the tool.
- Successful PDF report generation with accurate data.
- Processing time per test within acceptable limits (e.g., \< 60 seconds).
